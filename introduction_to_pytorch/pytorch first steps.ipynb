{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets define the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets test our activation function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create normally distributed numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3299, -0.0124,  2.6945]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squish them between 0 to 1. Observe that numbers which are large, get close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5817, 0.4969, 0.9367]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets do some math with features and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3301,  0.5344,  1.6967, -1.2788,  1.5472]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.randn((1, 5))\n",
    "features\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6660, -1.2729,  1.2155, -1.0954,  0.3891]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.randn_like(features)\n",
    "weights\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are of type tensors. A tensor is just a generalisation of vectors and matrices. These are the basic data structures used to build a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0849,  0.0456,  0.2698, -0.4198,  0.8317]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features * weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08493"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2235 * -0.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by using \"*\" we are just doing element wise multiplication. We want to do matrix multiplication of these two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function mm:\n",
      "\n",
      "mm(...)\n",
      "    mm(input, mat2, out=None) -> Tensor\n",
      "    \n",
      "    Performs a matrix multiplication of the matrices :attr:`input` and :attr:`mat2`.\n",
      "    \n",
      "    If :attr:`input` is a :math:`(n \\times m)` tensor, :attr:`mat2` is a\n",
      "    :math:`(m \\times p)` tensor, :attr:`out` will be a :math:`(n \\times p)` tensor.\n",
      "    \n",
      "    .. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
      "              For broadcasting matrix products, see :func:`torch.matmul`.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the first matrix to be multiplied\n",
      "        mat2 (Tensor): the second matrix to be multiplied\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> mat1 = torch.randn(2, 3)\n",
      "        >>> mat2 = torch.randn(3, 3)\n",
      "        >>> torch.mm(mat1, mat2)\n",
      "        tensor([[ 0.4851,  0.5037, -0.3633],\n",
      "                [-0.0760, -3.6705,  2.4784]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the column sizes must match for doing matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6424]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(features, weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add some bias to this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8929]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = torch.randn((1, 1))\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function sum:\n",
      "\n",
      "sum(...)\n",
      "    sum(input, dtype=None) -> Tensor\n",
      "    \n",
      "    Returns the sum of all elements in the :attr:`input` tensor.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "            is performed. This is useful for preventing data type overflows. Default: None.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(1, 3)\n",
      "        >>> a\n",
      "        tensor([[ 0.1133, -0.9567,  0.2958]])\n",
      "        >>> torch.sum(a)\n",
      "        tensor(-0.5475)\n",
      "    \n",
      "    .. function:: sum(input, dim, keepdim=False, dtype=None) -> Tensor\n",
      "    \n",
      "    Returns the sum of each row of the :attr:`input` tensor in the given\n",
      "    dimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\n",
      "    reduce over all of them.\n",
      "    \n",
      "    \n",
      "    If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "    as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
      "    Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "    output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
      "    \n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "        dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
      "        keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "            is performed. This is useful for preventing data type overflows. Default: None.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(4, 4)\n",
      "        >>> a\n",
      "        tensor([[ 0.0569, -0.2475,  0.0737, -0.3429],\n",
      "                [-0.2993,  0.9138,  0.9337, -1.6864],\n",
      "                [ 0.1132,  0.7892, -0.1003,  0.5688],\n",
      "                [ 0.3637, -0.9906, -0.4752, -1.5197]])\n",
      "        >>> torch.sum(a, 1)\n",
      "        tensor([-0.4598, -0.1381,  1.3708, -2.6217])\n",
      "        >>> b = torch.arange(4 * 5 * 6).view(4, 5, 6)\n",
      "        >>> torch.sum(b, (2, 1))\n",
      "        tensor([  435.,  1335.,  2235.,  3135.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore torch.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5372, -1.1006, -0.1742,  2.2311],\n",
       "        [ 1.1747, -0.1617, -1.8551,  0.8190],\n",
       "        [-1.2993,  1.3731,  1.2524,  0.1761],\n",
       "        [ 0.8311, -1.0283,  0.9312,  0.4102]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4936, -0.0230,  1.5022,  1.1442])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4935"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([ 0.5372, -1.1006, -0.1742,  2.2311])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, by giving 1 we are getting sum on row wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2438, -0.9177,  0.1544,  3.6364])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2437"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([ 0.5372, 1.1747, -1.2993, 0.8311])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, by giving 0 we are getting sum on column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function arange:\n",
      "\n",
      "arange(...)\n",
      "    arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "    \n",
      "    Returns a 1-D tensor of size :math:`\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil`\n",
      "    with values from the interval ``[start, end)`` taken with common difference\n",
      "    :attr:`step` beginning from `start`.\n",
      "    \n",
      "    Note that non-integer :attr:`step` is subject to floating point rounding errors when\n",
      "    comparing against :attr:`end`; to avoid inconsistency, we advise adding a small epsilon to :attr:`end`\n",
      "    in such cases.\n",
      "    \n",
      "    .. math::\n",
      "        \\text{out}_{{i+1}} = \\text{out}_{i} + \\text{step}\n",
      "    \n",
      "    Args:\n",
      "        start (Number): the starting value for the set of points. Default: ``0``.\n",
      "        end (Number): the ending value for the set of points\n",
      "        step (Number): the gap between each pair of adjacent points. Default: ``1``.\n",
      "        out (Tensor, optional): the output tensor.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`). If `dtype` is not given, infer the data type from the other input\n",
      "            arguments. If any of `start`, `end`, or `stop` are floating-point, the\n",
      "            `dtype` is inferred to be the default dtype, see\n",
      "            :meth:`~torch.get_default_dtype`. Otherwise, the `dtype` is inferred to\n",
      "            be `torch.int64`.\n",
      "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "            Default: ``torch.strided``.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.arange(5)\n",
      "        tensor([ 0,  1,  2,  3,  4])\n",
      "        >>> torch.arange(1, 4)\n",
      "        tensor([ 1,  2,  3])\n",
      "        >>> torch.arange(1, 2.5, 0.5)\n",
      "        tensor([ 1.0000,  1.5000,  2.0000])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.arange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function view:\n",
      "\n",
      "view(...) method of torch.Tensor instance\n",
      "    view(*shape) -> Tensor\n",
      "    \n",
      "    Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "    different :attr:`shape`.\n",
      "    \n",
      "    The returned tensor shares the same data and must have the same number\n",
      "    of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "    view size must be compatible with its original size and stride, i.e., each new\n",
      "    view dimension must either be a subspace of an original dimension, or only span\n",
      "    across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "    contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "    \n",
      "    .. math::\n",
      "    \n",
      "      \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "    \n",
      "    Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "    without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "    :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "    returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "    :meth:`contiguous`) otherwise.\n",
      "    \n",
      "    Args:\n",
      "        shape (torch.Size or int...): the desired size\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> x = torch.randn(4, 4)\n",
      "        >>> x.size()\n",
      "        torch.Size([4, 4])\n",
      "        >>> y = x.view(16)\n",
      "        >>> y.size()\n",
      "        torch.Size([16])\n",
      "        >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "        >>> z.size()\n",
      "        torch.Size([2, 8])\n",
      "    \n",
      "        >>> a = torch.randn(1, 2, 3, 4)\n",
      "        >>> a.size()\n",
      "        torch.Size([1, 2, 3, 4])\n",
      "        >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "        >>> b.size()\n",
      "        torch.Size([1, 3, 2, 4])\n",
      "        >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "        >>> c.size()\n",
      "        torch.Size([1, 3, 2, 4])\n",
      "        >>> torch.equal(b, c)\n",
      "        False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(a.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   1,   2,   3,   4,   5],\n",
       "         [  6,   7,   8,   9,  10,  11],\n",
       "         [ 12,  13,  14,  15,  16,  17],\n",
       "         [ 18,  19,  20,  21,  22,  23],\n",
       "         [ 24,  25,  26,  27,  28,  29]],\n",
       "\n",
       "        [[ 30,  31,  32,  33,  34,  35],\n",
       "         [ 36,  37,  38,  39,  40,  41],\n",
       "         [ 42,  43,  44,  45,  46,  47],\n",
       "         [ 48,  49,  50,  51,  52,  53],\n",
       "         [ 54,  55,  56,  57,  58,  59]],\n",
       "\n",
       "        [[ 60,  61,  62,  63,  64,  65],\n",
       "         [ 66,  67,  68,  69,  70,  71],\n",
       "         [ 72,  73,  74,  75,  76,  77],\n",
       "         [ 78,  79,  80,  81,  82,  83],\n",
       "         [ 84,  85,  86,  87,  88,  89]],\n",
       "\n",
       "        [[ 90,  91,  92,  93,  94,  95],\n",
       "         [ 96,  97,  98,  99, 100, 101],\n",
       "         [102, 103, 104, 105, 106, 107],\n",
       "         [108, 109, 110, 111, 112, 113],\n",
       "         [114, 115, 116, 117, 118, 119]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.arange(4 * 5 * 6).view(4, 5, 6)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 435, 1335, 2235, 3135])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(b, (2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9765]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(torch.mm(features, weights.T) + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack them up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f58351aac90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3171]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)                     # Set the random seed so things are predictable\n",
    "\n",
    "features = torch.randn((1, 3))           # Features are 3 random normal variables\n",
    "\n",
    "rows, cols = features.shape\n",
    "n_inputs = cols                          # Number of input units\n",
    "n_hidden = 2                             # Number of hidden units\n",
    "n_output = 1                             # Number of output units\n",
    "\n",
    "w1 = torch.randn((n_inputs, n_hidden))   # Weights of hidden layer\n",
    "w2 = torch.randn((n_hidden, n_output))   # Weights of output layer\n",
    "\n",
    "bias1 = torch.randn((1, n_hidden))       # Bias for hidden layer\n",
    "bias2 = torch.randn((1, n_output))       # Bias for output layer\n",
    "\n",
    "h1 = sigmoid(torch.mm(features, w1) + bias1) # Output hidden layer\n",
    "h2 = sigmoid(torch.mm(h1, w2) + bias2)       # Output layer\n",
    "h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the output of our small neural network is 0.3171"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch to numpy and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71631457, 0.42575967, 0.9241998 ],\n",
       "       [0.27314966, 0.66047041, 0.3009574 ],\n",
       "       [0.38655754, 0.98479923, 0.83085797],\n",
       "       [0.02493058, 0.68285593, 0.07353881]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(4,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7163, 0.4258, 0.9242],\n",
       "        [0.2731, 0.6605, 0.3010],\n",
       "        [0.3866, 0.9848, 0.8309],\n",
       "        [0.0249, 0.6829, 0.0735]], dtype=torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71631457, 0.42575967, 0.9241998 ],\n",
       "       [0.27314966, 0.66047041, 0.3009574 ],\n",
       "       [0.38655754, 0.98479923, 0.83085797],\n",
       "       [0.02493058, 0.68285593, 0.07353881]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
